[{"content":"Contention in java.util.Random it\u0026rsquo;s thread-safe it\u0026rsquo;s lock-free To better understand this, let\u0026rsquo;s see how one of its primary operations, next(int), is implemented:\n1 2 3 4 5 6 7 8 9 protected int next(int bits) { long oldseed, nextseed; AtomicLong seed = this.seed; do { oldseed = seed.get(); nextseed = (oldseed * multiplier + addend) \u0026amp; mask; } while (!seed.compareAndSet(oldseed, nextseed)); return (int)(nextseed \u0026gt;\u0026gt;\u0026gt; (48 - bits)); } Instead of a dedicated instance of Random per thread, each thread only needs to maintain its own seed value. As of Java 8, the Thread class itself has been retrofitted to maintain the seed value:\n1 2 3 4 5 6 7 8 9 10 11 12 public class Thread implements Runnable { // omitted @jdk.internal.vm.annotation.Contended(\u0026#34;tlr\u0026#34;) long threadLocalRandomSeed; @jdk.internal.vm.annotation.Contended(\u0026#34;tlr\u0026#34;) int threadLocalRandomProbe; @jdk.internal.vm.annotation.Contended(\u0026#34;tlr\u0026#34;) int threadLocalRandomSecondarySeed; } The threadLocalRandomSeed variable is responsible for maintaining the current seed value for ThreadLocalRandom. Moreover, the secondary seed, threadLocalRandomSecondarySeed, is usually used internally by the likes of ForkJoinPool.\nThis implementation incorporates a few optimizations to make ThreadLocalRandom even more performant:\nAvoiding false sharing by using the @Contented annotation, which basically adds enough padding to isolate the contended variables in their own cache lines Using sun.misc.Unsafe to update these three variables instead of using the Reflection API Avoiding extra hashtable lookups associated with the ThreadLocal implementation Contention in java.util.SecureRandom it\u0026rsquo;s the subclass of java.util.Random\none of the most common locking issues within Java applications is triggered through an innocent-looking java.io.File.createTempFile() calls. Under the hood, this temporary file creation is relying upon a SecureRandom class to calculate the name of the file.\n1 2 3 4 5 6 7 8 9 10 private static final SecureRandom random = new SecureRandom(); static File generateFile(String prefix, String suffix, File dir) { long n = random.nextLong(); if (n == Long.MIN_VALUE) { n = 0; // corner case } else { n = Math.abs(n); } return new File(dir, prefix + Long.toString(n) + suffix); } And SecureRandom, when nextLong is called, eventually calls its method nextBytes(), which is defined as synchronized:\n1 2 3 synchronized public void nextBytes(byte[] bytes) { secureRandomSpi.engineNextBytes(bytes); } One may say, that if I create new SecureRandom in each thread, I will not get any issues. Unfortunately, it’s not that simple. SecureRandom uses an implementation of java.security.SecureRandomSpi, which will eventually be contended anyhow (you may look at the following bug discussion with some benchmarks in Jenkins issue tracker)\nThis in combination with certain application usage patterns (especially if you have lots of SSL connections which rely on SecureRandom for their crypto-handshaking magic) has a tendency to build up into long-lasting contention issues.\nThe fix to the situation is simple if you can control the source code – just rebuild the solution to rely upon the java.util.ThreadLocalRandom for multithreaded designs. In cases where you are stuck with a standard API making the decisions for you the solution can be more complex and require significant refactoring.\nurandom and random Devices https://www.ibm.com/docs/en/aix/7.2?topic=files-urandom-random-devices\nLinux Kernel 5.8 之前的版本，如果熵池的数据不足，从 /dev/random 读取数据可能阻塞，但是从 /dev/urandom 不会阻塞。Java 程序一般会指定 -Djava.security.egd=file:/dev/./urandom 参数避免阻塞的发生(但不一定生效)。 需要注意的是，\n-Djava.security.egd=file:/dev/urandom 是错误的； -Djava.security.egd=file:/dev/./urandom 才是正确的； 见：https://stackoverflow.com/questions/137212/how-to-deal-with-a-slow-securerandom-generator 关于性能 ThreadLocalRandom 和 SecureRandom 都是 Random 的子类； 性能：ThreadLocalRandom \u0026gt; Random \u0026gt; SecureRandom； Random 和 ThreadLocalRandom 使用的都是「线性同余发生器」算法，速度很快，区别是： Random 使用 CAS 方式更新种子，高并发情况下竞争大，性能会下降； ThreadLocalRandom 将种子存在在 Thread 对象上，性能更好： 种子封闭在线程内，不需要 CAS； 避免额外的『间接』计算： 相比 ThreadLocal + Random，在 Java8 中，ThreadLocalRandom 只需要直接读取存储在 Thread 对象上的 threadLocalRandomSeed 然后直接更新就可以，不需要调用 ThreadLocal.get 进行一次 HashTable Lookup； 通过 UNSAFE 的 native 方法更新种子值，而不是反射，效率更高； 通过使用 Contended 注解，避免伪共享问题； SecureRandom 使用 OS 维护的随机数据来生成随机数，底层会使用 synchronized 锁，因此性能比较差，且可能发生阻塞； SecureRandom 使用的某些算法，需要读取 /dev/random 来获取随机数据，当 OS 维护的熵池中的熵不足时，会发生阻塞，导致严重的性能问题； 在 Linux 的 v5.6 及其以后的内核中，读取 /dev/random 不会再被阻塞了，但是就像 /dev/urandom 一样，在一个全新的系统刚启动时由于系统尚未产生熵值，此时还是可能阻塞等待足够的熵值产生； UUID.randomUUID 底层使用的就是 SecureRandom，因此性能会比较差； File.createTempFile 底层也会使用 SecureRandom，因此性能会比较差； 建立 SSL 连接同样依赖 SecureRandom，因此也要小心； 如何预测下一个随机数 以下方法仅对基于 LCG 算法有效，利用公式 𝑋𝑛+1=(𝑎𝑋𝑛+𝑐) mod 𝑚。\n给定两个连续的 int 类型值，或一个 double，或一个 long 类型值，即可预测后续的随机数。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 Predict Next Random Number.java import java.util.ArrayList; import java.util.Random; public class ReplicatedRandom extends Random { public static void main(String[] args) { predictByNextDouble(); predictByNextInt(); } private static void predictByNextInt() { long seed = System.currentTimeMillis(); Random r = new Random(seed); int v1 = r.nextInt(); int v2 = r.nextInt(); ReplicatedRandom rr = new ReplicatedRandom(); rr.replicateState(v1, v2); System.out.println(r.nextInt() == rr.nextInt()); // True System.out.println(r.nextInt() == rr.nextInt()); // True System.out.println(r.nextInt() == rr.nextInt()); // True } private static void predictByNextDouble() { long seed = System.currentTimeMillis(); Random r = new Random(seed); ReplicatedRandom rr = new ReplicatedRandom(); rr.replicateState(r.nextDouble()); System.out.println(r.nextDouble() == rr.nextDouble()); // True System.out.println(r.nextDouble() == rr.nextDouble()); // True System.out.println(r.nextDouble() == rr.nextDouble()); // True } // Replicate the state of a Random using a single value from its nextDouble public boolean replicateState(double nextDouble) { // nextDouble() is generated from ((next(26) \u0026lt;\u0026lt; 27) + next(27)) / (1L \u0026lt;\u0026lt; 53) // Inverting those operations will get us the values of next(26) and next(27) long numerator = (long) (nextDouble * (1L \u0026lt;\u0026lt; 53)); int first26 = (int) (numerator \u0026gt;\u0026gt;\u0026gt; 27); int last27 = (int) (numerator \u0026amp; ((1L \u0026lt;\u0026lt; 27) - 1)); return replicateState(first26, 26, last27, 27); } // Replicate the state of a Random using a single value from its nextLong public boolean replicateState(long nextLong) { int last32 = (int) (nextLong \u0026amp; ((1L \u0026lt;\u0026lt; 32) - 1)); int first32 = (int) ((nextLong - last32) \u0026gt;\u0026gt; 32); return replicateState(first32, 32, last32, 32); } // Replicate the state of a Random using two consecutive values from its nextInt public boolean replicateState(int firstNextInt, int secondNextInt) { return replicateState(firstNextInt, 32, secondNextInt, 32); } // Replicate the state of a Random using two consecutive values from its nextFloat public boolean replicateState(float firstNextFloat, float secondNextFloat) { return replicateState((int) (firstNextFloat * (1 \u0026lt;\u0026lt; 24)), 24, (int) (secondNextFloat * (1 \u0026lt;\u0026lt; 24)), 24); } public boolean replicateState(int nextN, int n, int nextM, int m) { // Constants copied from java.util.Random final long multiplier = 0x5DEECE66DL; final long addend = 0xBL; final long mask = (1L \u0026lt;\u0026lt; 48) - 1; long upperMOf48Mask = ((1L \u0026lt;\u0026lt; m) - 1) \u0026lt;\u0026lt; (48 - m); // next(x) is generated by taking the upper x bits of 48 bits of (oldSeed * multiplier + addend) mod (mask + 1) // So now we have the upper n and m bits of two consecutive calls of next(n) and next(m) long oldSeedUpperN = ((long) nextN \u0026lt;\u0026lt; (48 - n)) \u0026amp; mask; long newSeedUpperM = ((long) nextM \u0026lt;\u0026lt; (48 - m)) \u0026amp; mask; // Bruteforce the lower (48 - n) bits of the oldSeed that was truncated. // Calculate the next seed for each guess of oldSeed and check if it has the same top m bits as our newSeed. // If it does then the guess is right and we can add that to our candidate seeds. ArrayList\u0026lt;Long\u0026gt; possibleSeeds = new ArrayList\u0026lt;Long\u0026gt;(); for (long oldSeed = oldSeedUpperN; oldSeed \u0026lt;= (oldSeedUpperN | ((1L \u0026lt;\u0026lt; (48 - n)) - 1)); oldSeed++) { long newSeed = (oldSeed * multiplier + addend) \u0026amp; mask; if ((newSeed \u0026amp; upperMOf48Mask) == newSeedUpperM) { possibleSeeds.add(newSeed); } } if (possibleSeeds.size() == 1) { // If there\u0026#39;s only one candidate seed, then we found it! setSeed(possibleSeeds.get(0) ^ multiplier); // setSeed(x) sets seed to `(x ^ multiplier) \u0026amp; mask`, so we need another `^ multiplier` to cancel it out return true; } if (possibleSeeds.size() \u0026gt;= 1) { System.out.println(\u0026#34;Didn\u0026#39;t find a unique seed. Possible seeds were: \u0026#34; + possibleSeeds); } else { System.out.println(\u0026#34;Failed to find seed!\u0026#34;); } return false; } } 说明：\n上面的算法利用了 Java 生成的随机数有 48 个有效位这一信息； 对于 nextInt 来说，返回值是 32 位，因此在返回结果时，会舍弃低 16 位，这是通过 \u0026raquo;\u0026gt; 位移操作实现的； 对于 nextLong 来说，它是由两个连续的 nextInt 组成的； 对于 nextDouble 来说，它是由两个连续的分别是 27 bits 和 26 bits 数字组成的； 因此，当给定一个 nextInt 值时，将其左移 16 位，即得到种子的最小可能值，该值加上 2^16 - 1，就是种子的最大可能值；因此，只需遍历该空间(包含 2^16 个数字)，即可推测出种子的实际值； 现代 CPU 可以在 1 秒内用暴力方法逆向的推测出当前的种子值； Benchmark 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 RandomBenchmark.java package benchmark; import org.openjdk.jmh.annotations.Benchmark; import org.openjdk.jmh.annotations.BenchmarkMode; import org.openjdk.jmh.annotations.Fork; import org.openjdk.jmh.annotations.Measurement; import org.openjdk.jmh.annotations.Mode; import org.openjdk.jmh.annotations.OutputTimeUnit; import org.openjdk.jmh.annotations.Scope; import org.openjdk.jmh.annotations.State; import org.openjdk.jmh.annotations.Threads; import org.openjdk.jmh.annotations.Warmup; import org.openjdk.jmh.results.format.ResultFormatType; import org.openjdk.jmh.runner.Runner; import org.openjdk.jmh.runner.RunnerException; import org.openjdk.jmh.runner.options.Options; import org.openjdk.jmh.runner.options.OptionsBuilder; import java.time.LocalDateTime; import java.time.format.DateTimeFormatter; import java.util.Random; import java.util.concurrent.ThreadLocalRandom; import java.util.concurrent.TimeUnit; /** */ @BenchmarkMode({Mode.AverageTime, Mode.Throughput}) @Warmup(iterations = 3, time = 1) @Measurement(iterations = 5, time = 5) @Threads(4) @Fork(1) @State(value = Scope.Benchmark) @OutputTimeUnit(TimeUnit.NANOSECONDS) public class RandomBenchmark { private final Random random = new Random(); private final ThreadLocal\u0026lt;Random\u0026gt; simpleThreadLocal = ThreadLocal.withInitial(Random::new); public static void main(String[] args) throws RunnerException { // 将结果文件上传到 https://jmh.morethan.io/ 可以得到可视化结果 String now = LocalDateTime.now().format(DateTimeFormatter.ofPattern(\u0026#34;yyyyMMddHHmmss\u0026#34;)); String filePath = \u0026#34;/tmp/jmh_result_\u0026#34; + now + \u0026#34;.json\u0026#34;; Options opt = new OptionsBuilder() .include(RandomBenchmark.class.getSimpleName()) .result(filePath) .resultFormat(ResultFormatType.JSON).build(); new Runner(opt).run(); } @Benchmark // @BenchmarkMode(Throughput) public int regularRandom() { return random.nextInt(); } @Benchmark // @BenchmarkMode(Throughput) public int simpleThreadLocal() { return simpleThreadLocal.get().nextInt(); } @Benchmark // @BenchmarkMode(Throughput) public int builtinThreadLocal() { return ThreadLocalRandom.current().nextInt(); } } Reference https://www.baeldung.com/java-thread-local-random https://alidg.me/blog/2020/4/24/thread-local-random https://stackoverflow.com/questions/11051205/difference-between-java-util-random-and-java-security-securerandom https://resources.infosecinstitute.com/topic/random-number-generation-java/ https://jazzy.id.au/2010/09/21/cracking_random_number_generators_part_2.html https://jazzy.id.au/2010/09/22/cracking_random_number_generators_part_3.html https://blogs.oracle.com/linux/post/rngd1 https://blogweb.cn/article/1642969777211 https://lwn.net/Articles/808575/ https://unix.stackexchange.com/questions/243127/how-to-check-if-reading-from-dev-random-will-block https://crypto.stackexchange.com/questions/51686/how-to-determine-the-next-number-from-javas-random-method https://franklinta.com/2014/08/31/predicting-the-next-math-random-in-java/ https://jazzy.id.au/2010/09/20/cracking_random_number_generators_part_1.html (讲解了破解随机数生成器的理论基础) ","date":"2023-01-30T10:33:47+08:00","permalink":"https://zhumengzhu.github.io/2023/01/java-random-number-issues-overview/","title":"Java 随机数问题综述"},{"content":"简介 本文从『优惠券发放』问题的讨论出发，介绍几个解决方案并分析其优缺点，然后讨论一下常见的update just one unused row模式，最后聊一下 MySQL 8.0.1 的 SKIP LOCKED 和 NOWAIT 特性。\n『券发放』问题 券发放，一般使用『预生成』模式。在发放前，先将券全部生成好，存在一张全表，这张表一般至少包含三个字段：\n一个全局唯一的券码字段； 一个状态字段表示是否发放； 一个用户 ID 字段记录券发给了谁； 当用户请求领券时，会从表中选择一条状态为『未领取』的记录，将其状态置为『已领取』，用户 ID置为『领券者的 ID』，最后将券码返给用户。\n假设券表结构如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 CREATE TABLE `coupon` ( `id` BIGINT(20) NOT NULL AUTO_INCREMENT COMMENT \u0026#39;主键id\u0026#39;, `code` VARCHAR(64) NOT NULL DEFAULT \u0026#39;\u0026#39; COMMENT \u0026#39;唯一劵码\u0026#39;, `status` TINYINT(10) NOT NULL DEFAULT 0 COMMENT \u0026#39;劵状态, 0: 未领取，1：已领取，2：已核销\u0026#39;, `user_id` BIGINT(20) NOT NULL DEFAULT 0 COMMENT \u0026#39;用户 ID\u0026#39;, `create_time` DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP, `update_time` DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP, PRIMARY KEY (`id`), UNIQUE KEY `uk_code` (`code`), KEY `idx_status` (`status`) ) ENGINE = InnoDB DEFAULT CHARSET = utf8mb4 COMMENT =\u0026#39;优惠券表\u0026#39;; 券表中的数据如下：\nID CODE status user_id 1 c1 0 0 2 c2 0 0 3 c3 0 0 4 c4 0 0 5 c5 0 0 假设领券的用户 ID 为 1000。\n方法一：乐观锁-CAS 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # 1、选择一张券，假设选中的券码为 `c1`； SELECT * FROM coupon WHERE `status` = 0 LIMIT 1; # 2、修改券记录的状态 UPDATE coupon SET `status` = 1, `user_id` = 1000 WHERE `code` = \u0026#39;c1\u0026#39; AND `status` = 0; # 3、返回券码 `c1` 上述方法，在并发情况下可能存在问题：\n操作顺序 线程一 线程二 1 SELECT * FROM coupon WHERE status = 0 LIMIT 1; # 假设返回记录券码为 c1 2 SELECT * FROM coupon WHERE status = 0 LIMIT 1; # 假设返回记录券码也是 c1 3 UPDATE coupon SET status = 1, user_id = 1000 WHERE code = \u0026lsquo;c1\u0026rsquo; AND status = 0; # 成功 4 UPDATE coupon SET status = 1, user_id = 1000 WHERE code = \u0026lsquo;c1\u0026rsquo; AND status = 0; # 失败 由于线程一执行完第三步后，已将c1这条记录的status的值改为 1，因此线程二执行第四步会失败。所以需要重试。\n这可以看做一种『乐观锁』模式，『乐观锁』不适合高并发场景。\n方法二：悲观锁-SELECT FOR UPDATE 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 # 1、开启事务（InnoDB 默认的 RR 级别） begin; # 2、选择一张券，假设选中的券码为 `c1`； SELECT * FROM coupon WHERE `status` = 0 LIMIT 1 FOR UPDATE; # 3、修改券记录的状态 UPDATE coupon SET `status` = 1, `user_id` = 1000 WHERE `code` = \u0026#39;c1\u0026#39; AND `status` = 0; # 4、提交事务 commit; # 5、返回券码 `c1` 为了解决并发的情况下某个操作失败， 可以开启一个事务，然后使用 select for update 先对记录进行加锁，然后再修改记录状态。 假设操作顺序如下：\n操作顺序 线程一 线程二 1 begin; 2 begin; 3 SELECT * FROM coupon WHERE status = 0 LIMIT 1 FOR UPDATE; # 假设返回记录券码为 c1 4 SELECT * FROM coupon WHERE status = 0 LIMIT 1 FOR UPDATE; # 阻塞 5 UPDATE coupon SET status = 1, user_id = 1000 WHERE code = \u0026lsquo;c1\u0026rsquo; AND status = 0; # 成功 6 commit; # 释放记录c1的锁 7 SELECT * FROM coupon WHERE status = 0 LIMIT 1; # 成功，返回券码 c2 8 UPDATE coupon SET status = 1, user_id = 1000 WHERE code = \u0026lsquo;c2\u0026rsquo; AND status = 0; # 成功 9 commit; # 释放记录c2的锁 线程二在执行第 4 步时，由于线程一已经抢到记录c1的锁，线程二会被阻塞，直到线程一提交事务（ 根据2PL，提交事务时才会释放锁）；线程二在 7 步获取锁后，由于记录c1的status的值已被线程一改为 1，所以此时查询到的记录是c2。\n方法二虽然可以保证券发放不会失败，但在高并发下，会有大量线程阻塞。\n方法三：使用 LAST_INSERT_ID 优化锁的持有时间 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # 1、将状态为未领取的一张券发放给用户 UPDATE coupon SET `status` = 1, `user_id` = 1000, `id` = LAST_INSERT_ID(`id`) WHERE `status` = 0 LIMIT 1; # 2、查询步骤 1 修改的券的 ID，假设 id 为 1 SELECT LAST_INSERT_ID(); # 3、查询券码，假设券码值为 `c1` SELECT `code` FROM coupon WHERE id = 1; # 4、返回券码 `c1` 方法二中，根据 2PL（两阶段锁协议），锁的持有时间从 select for update 一直持续到 commit。 通过使用 LAST_INSERT_ID 可以避免开启事务，锁的持有时间非常短。\n不过这个方法没法避免锁争抢，因为根据 InnoDB 的锁机制，在扫描到满足条件的记录时会进行加锁(由于 idx_status 是非唯一索引，因此会加 next-key 锁) ，所以并发执行时仍然会存在阻塞的情况。\n这其实就是经典的**『热点数据更新』**问题。\n此外，要这个方法是 multi-user safe 的，所以在并发情况下也是安全的:\nIt is multi-user safe because multiple clients can issue the UPDATE statement and get their own sequence value with the SELECT statement (or mysql_insert_id()), without affecting or being affected by other clients that generate their own sequence values.\nsee MySQL 8.0 Reference Manual\n最后，还可以对上面的 SQL 进一步优化，使得只需执行 2 次 SQL：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # 1、将状态为未领取的一张券发放给用户 UPDATE coupon SET `status` = 1, `user_id` = 1000, `id` = LAST_INSERT_ID(`id`) WHERE `status` = 0 LIMIT 1; # 2、查询券码 SELECT `code` FROM coupon, (SELECT LAST_INSERT_ID() id) AS t WHERE coupon.id = t.id; # 3、返回券码 `c1` 方法四：使用 SKIP LOCKED 避免锁争抢 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 # 1、开启事务（InnoDB 默认的 RR 级别） begin; # 2、是用 `SELECT FOR UPDATE SKIP LOCKED` 选择一条券 SELECT * FROM coupon WHERE `status` = 0 LIMIT 1 FOR UPDATE SKIP LOCKED; # 3、修改券记录的状态 UPDATE coupon SET `status` = 1, `user_id` = 1000 WHERE `code` = \u0026#39;c1\u0026#39; AND `status` = 0; # 4、提交事务 commit; # 5、返回券码 `c1` 假设操作顺序如下：\n操作顺序 线程一 线程二 1 begin; 2 begin; 3 SELECT * FROM coupon WHERE status = 0 LIMIT 1 FOR UPDATE SKIP LOCKED; # 假设返回记录券码为 c1 4 SELECT * FROM coupon WHERE status = 0 LIMIT 1 FOR UPDATE SKIP LOCKED; # 成功，返回券码 c2 5 UPDATE coupon SET status = 1, user_id = 1000 WHERE code = \u0026lsquo;c1\u0026rsquo; AND status = 0; # 成功 6 commit; # 释放记录c1的锁 8 UPDATE coupon SET status = 1, user_id = 1000 WHERE code = \u0026lsquo;c2\u0026rsquo; AND status = 0; # 成功 9 commit; # 释放记录c2的锁 不同于方法二，线程二在执行第 4 步时，不会阻塞在记录c1上，而是会跳过这条记录，直接对下一条记录c2进行加锁。\n这个方法，锁的持有时间与方法二相同，但避免了争抢锁，也能达到一个很好的性能。\n注意，SKIP LOCKED 是 MySQL 8.0.1 引入的新特性。\n方法五：使用 Redis 减少 SQL 的执行次数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # 0、初始化 Redis: 在活动开始前，先从数据库中查询所有未发放券的券码，放入 Redis 中的队列中 LPUSH coupon_list_key (SELECT code from coupon WHERE status = 0) # 1、发放时，从 Redis 队列中移除并返回一个券码，假设值为`c1` LPOP coupon_list_key # 2、修改券记录的状态 UPDATE coupon SET `status` = 1, `user_id` = 1000 WHERE `code` = \u0026#39;c1\u0026#39; AND `status` = 0; # 3、返回券码 `c1` 使用 Redis，既能保证正确性，也有更好的性能，因为：\nRedis 是单线程执行命令的，因此从 Redis 返回的券码是唯一的，执行第 2 步不会争抢锁也不会失败； LPOP 命令是从队列头移除一个元素，时间复杂度仅为 O(1)； 仅需要执行一条 UPDATE 语句； 除此之外，还可以通过引入 MQ 将 UPDATE 语句改为异步执行，进一步提高并发度。\n不过，引入 Redis 会使得系统变得更复杂，因为：\n需要额外编写一个模块用来初始化 Redis； 在初始化 Redis 要特别小心，不能将『已发放』的券放入 Redis； 从 Redis 出队成功，但写数据库失败，会导致券码被浪费，需要回滚 Redis； 回滚 Redis 可能实现起来比较复杂，因为将券码放回 Redis 时可能失败，需要重试机； Redis 主从同步可能存在延迟，此时主从切换可能导致 Redis 返回重复的券码，导致方法失败，需要重试机制； 小节 方法一和方法二不适合高并发场景，前者失败率高，后者性能特别差； 方法三持有锁的时间很短，性能比较好，实现也很简单，但存在热点数据更新问题； 方法四持有锁的时间稍长，因为锁的是不同的记录，因此不存在热点数据，性能比较好，实现也简单，但只能在 MySQL 8.0.1 及以上才能使用； 方法五引入 Redis，在性能上有最大的潜力，但实现起来更复杂； 方法三、四、五孰优孰劣，留待实践进行检验。\nUpdate just one unused row 仅更新一行未使用的数据，是一种非常常见的场景，看似非常容易解决：\n1 2 3 4 5 # 乐观锁 CAS 更新 UPDATE record SET `status` = \u0026#39;used\u0026#39; WHERE `status` = \u0026#39;unused\u0026#39; LIMIT 1; 但当我们需要获取被更新数据的 ID 时，问题瞬间变得复杂起来。\n获取变更 ID，除了上面介绍的使用悲观锁SELECT FOR UPDATE和LAST_INSERT_ID两个方法外，还可以通过临时变量来实现：\nSET @update_id := 0; UPDATE some_table SET column_name = \u0026lsquo;value\u0026rsquo;, id = (SELECT @update_id := id) WHERE some_other_column = \u0026lsquo;blah\u0026rsquo; LIMIT 1; SELECT @update_id;\n详情见：How to get ID of the last updated row in MySQL?:\n这种方法在需要一次更新多条记录时特别有用。\nMySQL 8.0.1 SKIP LOCKED and NOWAIT 推荐一篇文章：MySQL 8.0.1: Using SKIP LOCKED and NOWAIT to handle hot rows 这篇文章是在 2017 年 4 月 12 由 Martin Hansson 发布在 MySQL 官方博客上的。它主要是通过一个订票系统，讲解 SKIP LOCKED 和 NOWAIT 的使用方法。\n另外，需要特别注意：\nStatements that use NOWAIT or SKIP LOCKED are unsafe for statement based replication.\nReference https://dba.stackexchange.com/questions/131051/update-just-one-unused-row https://stackoverflow.com/questions/1388025/how-to-get-id-of-the-last-updated-row-in-mysql https://gist.github.com/PieterScheffers/189cad9510d304118c33135965e9cddb https://dev.mysql.com/blog-archive/mysql-8-0-1-using-skip-locked-and-nowait-to-handle-hot-rows/ https://dev.mysql.com/doc/refman/8.0/en/information-functions.html#function_last-insert-id https://dev.mysql.com/doc/refman/8.0/en/innodb-locking.html ","date":"2022-11-20T17:21:39+08:00","permalink":"https://zhumengzhu.github.io/2022/11/mysql-update-just-one-unused-row/","title":"Mysql 只更新未使用的一行数据问题"},{"content":"背景 这是一篇博客阅读笔记，原博客Late row lookups: InnoDB写于 2011 年，作者是一个叫 Quassnoi 的俄罗斯人。\nQuassnoi 在 2009 年时写了一篇文章讲 MySQL Limit 的性能优化(MySQL ORDER BY / LIMIT performance: late row lookups)，后来有读者提了两个问题：\nIs this workaround specific to MyISAM engine? How does PostgreSQL handle this? Quassnoi 写下这篇新博客，即为了回答上述两个问题。\n正文 The questions concerns a certain workaround for MySQL LIMIT … OFFSET queries like this:\n1 2 3 4 SELECT * FROM mytable ORDER BY id LIMIT 10 OFFSET 10000; which can be improved using a little rewrite:\n1 2 3 4 5 6 7 8 SELECT m.* FROM (SELECT id FROM mytable ORDER BY id LIMIT 10 OFFSET 10000) q JOIN mytable m ON m.id = q.id ORDER BY m.id; 注意：作者之前的文章讨论的是这个方法对 MyISAM 是有效的；问题是，对于 InnoDB 和 PostgreSQL 呢？\nPostgreSQL The Answer The second questions is easy: PostgreSQL won\u0026rsquo;t pull the fields from the table until it really needs them. If a query involving an ORDER BY along with LIMIT and OFFSET is optimized to use the index for the ORDER BY part, the table lookups won\u0026rsquo;t happen for the records skipped.\n这句话是说，PostgreSQL 只会在需要的时候才回表查询。如果一个查询涉及 ORDER BY、LIMIT 和 OFFSET，那么可以先利用索引跳过不需要的记录，只对需要的记录进行进行回表。\n这其实就是『Late Row Lookups』；与之相对的，MySQL 执行的是『Early Row Lookups』。\n作者后面说虽然 PostgreSQL 的查询计划不会输出回表信息，但可以通过一个简单的测试进行验证。但具体怎么进行这个实验，作者没讲，下面试着做个补充。\n验证(存疑) 建表详情 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 -- 建表 CREATE TABLE page ( id SERIAL PRIMARY KEY, name VARCHAR(16) DEFAULT NULL, content VARCHAR(255) DEFAULT NULL ); -- 为 name 字段创建二级索引 CREATE INDEX idx_name ON page (name); -- 初始化 600 万条数据 INSERT INTO page (name, content) (SELECT CONCAT(\u0026#39;小瓦\u0026#39;, s.id) AS name, CONCAT(\u0026#39;xx\u0026#39;, s.id) AS content FROM GENERATE_SERIES(1, 6000010) AS s(id)); 执行 SQL 一：直接查询 1 2 3 4 5 6 7 postgres=# EXPLAIN ANALYZE SELECT * FROM page ORDER BY id OFFSET 6000000 LIMIT 10; QUERY PLAN ------------------------------------------------------------------------------------------------------------------------------------------ Limit (cost=199830.43..199830.76 rows=10 width=26) (actual time=540.002..540.003 rows=10 loops=1) -\u0026gt; Index Scan using page_pkey on page (cost=0.43..199846.81 rows=6000492 width=26) (actual time=0.087..427.982 rows=6000010 loops=1) Planning Time: 0.108 ms Execution Time: 540.022 ms 执行 SQL 二：使用子查询 1 2 3 4 5 6 7 8 9 10 11 postgres=# EXPLAIN ANALYZE SELECT t1.* FROM page t1, (SELECT id FROM page ORDER BY id OFFSET 6000000 LIMIT 10) t2 where t1.id=t2.id ORDER BY t1.id; QUERY PLAN ---------------------------------------------------------------------------------------------------------------------------------------------------- Nested Loop (cost=155811.47..155895.90 rows=10 width=26) (actual time=368.952..368.960 rows=10 loops=1) -\u0026gt; Limit (cost=155811.04..155811.30 rows=10 width=4) (actual time=368.941..368.942 rows=10 loops=1) -\u0026gt; Index Only Scan using page_pkey on page (cost=0.43..155823.81 rows=6000492 width=4) (actual time=0.015..248.584 rows=6000010 loops=1) Heap Fetches: 50 -\u0026gt; Index Scan using page_pkey on page t1 (cost=0.43..8.45 rows=1 width=26) (actual time=0.001..0.001 rows=1 loops=10) Index Cond: (id = page.id) Planning Time: 0.375 ms Execution Time: 369.004 ms 执行 SQL 三：使用子查询 1 2 3 4 5 6 7 8 9 10 11 postgres=# EXPLAIN ANALYZE SELECT t1.* FROM page t1 join (SELECT id FROM page ORDER BY id OFFSET 6000000 LIMIT 10) t2 ON t1.id=t2.id ORDER BY t1.id; QUERY PLAN ---------------------------------------------------------------------------------------------------------------------------------------------------- Nested Loop (cost=155811.47..155895.90 rows=10 width=26) (actual time=362.645..362.652 rows=10 loops=1) -\u0026gt; Limit (cost=155811.04..155811.30 rows=10 width=4) (actual time=362.633..362.634 rows=10 loops=1) -\u0026gt; Index Only Scan using page_pkey on page (cost=0.43..155823.81 rows=6000492 width=4) (actual time=0.017..243.148 rows=6000010 loops=1) Heap Fetches: 50 -\u0026gt; Index Scan using page_pkey on page t1 (cost=0.43..8.45 rows=1 width=26) (actual time=0.001..0.001 rows=1 loops=10) Index Cond: (id = page.id) Planning Time: 4.609 ms Execution Time: 362.707 ms 三个查询的耗时为：`540.022 ms` vs `369.004 ms` vs `362.707 ms`。 \u003e Tips: 使用 `EXPLAIN ANALYZE` 既可以获得查询计划，又能执行语句。 结论 上述实验可以证明该优化对于 PostgreSQL 同样可以有效。\nInnoDB 为了回答这个问题，作者首先创建了一张表。\n建表 建表详情 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 # 创建一张内存表 CREATE TABLE filler ( id INT NOT NULL PRIMARY KEY AUTO_INCREMENT ) ENGINE = Memory; # 创建 InnoDB 表 CREATE TABLE lookup ( id INT NOT NULL PRIMARY KEY, value INT NOT NULL, shorttxt TEXT NOT NULL, longtxt TEXT NOT NULL ) ENGINE = InnoDB ROW_FORMAT = COMPACT; # 为 value 字段创建索引 CREATE INDEX ix_lookup_value ON lookup (value); # 创建存储计划 DELIMITER $$ CREATE PROCEDURE prc_filler(cnt INT) BEGIN DECLARE _cnt INT; SET _cnt = 1; WHILE _cnt \u0026lt;= cnt DO INSERT INTO filler SELECT _cnt; SET _cnt = _cnt + 1; END WHILE; END $$ # 初始化内存表 DELIMITER ; START TRANSACTION; CALL prc_filler(100000); COMMIT; # 初始化 InnoDB 表 INSERT INTO lookup SELECT id, CEILING(RAND(20110211) * 1000000), RPAD(\u0026#39;\u0026#39;, CEILING(RAND(20110211 \u0026lt;\u0026lt; 1) * 100), \u0026#39;*\u0026#39;), RPAD(\u0026#39;\u0026#39;, CEILING(8192 + RAND(20110211 \u0026lt;\u0026lt; 1) * 100), \u0026#39;*\u0026#39;) FROM filler; 上面利用一张内存表和存储计划创建了一张 InnoDB 表 `lookup`：这张表包含一个加了索引的 `INT` 列，以及两个 `TEXT` 列，其中 shorttxt 存储短字符串(包含 1~100 个字符)，longtxt 存储长字符串(包含 8193~8293 个字符)。 通过主键索引查询 value 和 shottxt 两个字段时，是否使用子查询优化对耗时影响不大，略去不讨论。\n通过主键索引查询 longtxt 列 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # Rewrite SELECT LENGTH(l.longtxt) FROM (SELECT id FROM lookup ORDER BY id LIMIT 10 OFFSET 90000) q JOIN lookup l ON l.id = q.id ORDER BY q.id; # 10 rows in set (0.133 sec) # No rewrite SELECT LENGTH(longtxt) FROM lookup ORDER BY id LIMIT 10 OFFSET 90000; # 10 rows in set (1.579 sec) 0.133 sec vs 1.579 sec。\nWhy such a difference?\nThe reason is that InnoDB, despite the fact it stores the data in the clustered index, is still able to move \u0026gt; some data out of the index. This is called external storage.\n在 InnoDB 中，小于 768 字节的列会全部存储在页上，大于 768 字节则会分开存储。在上面的 lookup 表中，shottxt 列总是 on-page 存储的，而 longtxt 则是 off-page的。\n因此，直接查询 longtxt 时，每扫描一条记录都要出发两次page lookups：第一次查聚簇索引，第二次查外部存储。这既会花费很多时间，也可能破坏 InnoDB 缓存，导致缓存命中率下降。\n通过二级索引查询 shorttxt 列 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # Rewrite SELECT LENGTH(l.shorttxt) FROM (SELECT id, value FROM lookup ORDER BY value LIMIT 10 OFFSET 90000) q JOIN lookup l ON l.id = q.id ORDER BY q.value; # 10 rows in set (0.022 sec) # No rewrite SELECT LENGTH(shorttxt) FROM lookup ORDER BY value LIMIT 10 OFFSET 90000;# 10 rows in set (0.209 sec) 0.022 sec vs 0.209 sec，耗时相差 10 倍。 InnoDB的二级索引查询有点类似MyISAM，都需要一次额外的回表查询去获取正在的数据。\n上面第一个查询对于跳过的记录不会执行回表查询，因此速度是原来的 10 倍。它甚至比在主键索引上的查询(0.044 sec)还快，原因是二级索引包含的数据比主键索引更少，每页保存的数据更多，因此索引可能更加矮胖，扫描速度更快。\n当然，二级索引上同样是Early Row Lookups。\n结论 A trick used to avoid early row lookups for the LIMIT … OFFSET queries is useful on InnoDB tables too, though to different extent, depending on the ORDER BY condition and the columns involved:\nIt\u0026rsquo;s very useful on queries involving columns stored off-page (long TEXT, BLOB and VARCHAR columns) It\u0026rsquo;s very useful on ORDER BY conditions served by secondary indexes It\u0026rsquo;s quite useful on moderate sized columns (still stored on page) or CPU-intensive expressions It\u0026rsquo;s almost useless on short columns without complex CPU-intensive processing 其它 PostgreSQL查询计划 除第一行以外每个-\u0026gt;表示一个子动作 查询计划的阅读顺序都是从后往前 cost 由 .. 分割成两个数字，第一个数字表示启动成本，即返回第一行的成本；第二个数字表示返回所有数据的成本。 rows 表示返回行数 width 表示每行平均宽度 loops 表示索引扫描被执行过几次 Reference Documentation: 15: 14.1. Using EXPLAIN - PostgreSQL ","date":"2022-11-14T19:12:47+08:00","permalink":"https://zhumengzhu.github.io/2022/11/late-row-lookups-innodb/","title":"Late Row Lookups: InnoDB"},{"content":"一、深分页为什么慢 深分页指的是形如 select ... from ... where ... order by ... limit offset, size 的查询语句中 offset 特别大的情况。高性能 MySQL(第三版) 的第 6.7.5 节专门讲了此问题，但比较简略。\n有多慢 假设有一张 page 表包含 600 多万条数据，分别执行下面两条语句：\n1 2 3 4 5 6 7 # SQL 一 select * from page order by id limit 0, 10; # 10 rows in set (0.001 sec) # SQL 二 select * from page order by id limit 6000000, 10; # 10 rows in set (0.940 sec) 注意到 SQL 二其实是按主键 ID 排序的(意味着不需要进行 filesort，直接按主键索引顺序扫描即可)，耗时仍然高达 0.940 秒。\n为什么慢 『查询计划』\n1 2 3 4 5 6 explain select * from page order by id limit 6000000, 10; +------+-------------+-------+-------+---------------+---------+---------+------+---------+-------+ | id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra | +------+-------------+-------+-------+---------------+---------+---------+------+---------+-------+ | 1 | SIMPLE | page | index | NULL | PRIMARY | 4 | NULL | 5988448 | | +------+-------------+-------+-------+---------------+---------+---------+------+---------+-------+ 『慢查询日志』\n1 2 3 4 5 6 7 # Time: 221106 0:26:54 # User@Host: root[root] @ localhost [] # Thread_id: 18 Schema: test QC_hit: No # Query_time: 0.939618 Lock_time: 0.000735 Rows_sent: 10 Rows_examined: 6000010 # Rows_affected: 0 Bytes_sent: 533 SET timestamp=1667665614; select * from page order by id limit 6000000, 10; 注意到 rows 和 为 rows_examined 分别为 5988448、6000010。 原因显而易见：为了完成 limit offset, size 这样的查询， MySQL 要扫描至少 offset + size 行数据；offset 越大，则扫描次数越多，速度越慢。\n二、深分页怎么优化 分页从原理上来讲，主要是两种：\n一种就是前面讲的基于 limit offset, size 的分页，英文一般叫 offset pagination； 另一种方法放弃了 offset，改用 left off, SQL 形如 SELECT ... WHERE ... AND id \u0026lt; $left_off ORDER BY id DESC LIMIT 10, 英文一般叫 cursor pagination, 也有人称之为 seek method 或 keyset pagination。 Offset pagination 就像基于比较的排序算法的平均时间复杂度的下界是 O(nlogn) 一样，对于 MySQL 来说，凡是形如 limit offset, size 的查询，扫描次数的下限就是 offset + size，我们只能尽量逼近这个下限。 由于在主键索引上的优化比较复杂，同样的 SQL 对于不同的数据规模效果不一样，暂不讨论。这里主要分析在二级索引上的优化。\n对于拥有 600 多万条数据的 page 表：\n1 2 3 4 5 6 7 8 9 10 -- 原 SQL(强制走二级索引) select * from page force index(idx_name) order by name limit 6000000, 10; # 10 rows in set (4.833 sec) -- 优化方案一 select t1.* from page t1, (select id from page order by name limit 6000000, 10) t2 where t1.id = t2.id order by t1.name; # 10 rows in set (0.746 sec) -- 优化方案二 select t1.* from page t1 join (select id from page order by name limit 6000000, 10) t2 on t1.id = t2.id order by t1.name; # 10 rows in set (0.741 sec) 通过使用利用了覆盖索引的子查询，性能提升约 80%~90%：\nKeyset pagination 1 2 3 4 # First page (latest 10 items): SELECT ... WHERE ... ORDER BY id DESC LIMIT 10 # Next page (second 10): SELECT ... WHERE ... AND id \u0026lt; $left_off ORDER BY id DESC LIMIT 10 三、优化为什么有效 优化前 考虑原始 SQL select * from page force index(idx_name) order by name limit 6000000, 10 的执行过程：\n首先 Sever 层向 InnoDB 请求第一条数据；InnoDB 从 idx_name 上获取第一条二级索引记录，然后查询聚簇索引获取完整记录(即回表操作)，返回给 Server 层; 由于存在 limit 6000000 的限制, Server 层会将该数据丢弃并计数，然后向 InnoDB 请求下一条数据； 上述操作重复 600 万次； 之后的第 6000001~6000010 10 条数据则会被放入本地网络缓冲区，发给客户端； 问题在第 1 步的回表操作：\n回表首先意味着先读一次二级索引，然后读一次聚簇索引，因此记录的扫描总数实际会是 2 * 600 万次=1200 万次； 其次，回表操作可能需要一次磁盘随机读； 优化后 再考虑优化后的 SQL select t1.* from page t1 join (select id from page order by name limit 6000000, 10) t2 on t1.id = t2.id order by t1.name 的执行过程：\n首先 Sever 层向 InnoDB 请求第一条数据；InnoDB 从 idx_name 上获取第一条二级索引记录，然后查询聚簇索引获取完整记录(这一操作叫回表)，然后将主键 ID 返回给 Server 层; 由于存在 limit 6000000 的限制, Server 层会将该数据丢弃并计数，然后向 InnoDB 请求下一条数据； 上述操作重复 600 万次； 之后的第 6000001~6000010 10 条数据则会被放入内存缓冲区； 查询聚簇索引，获取 10 个主键 ID 对应的完整记录； 总结 在优化后：\n记录的总扫描次数从 1200 万次 减少到 600 万零 10 次； 磁盘随机读的次数从 600 万次 减少到 10 次； 四、试验方法 建表和数据初始化 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 -- 建表 CREATE TABLE `page` ( `id` INT(11) NOT NULL AUTO_INCREMENT, `name` VARCHAR(16) DEFAULT NULL, `content` VARCHAR(255) DEFAULT NULL, PRIMARY KEY (`id`), KEY `idx_name` (`name`) ) ENGINE = InnoDB DEFAULT CHARSET = utf8mb4; -- 创建存储过程用于初始化数据 DELIMITER ;; CREATE PROCEDURE init_page() BEGIN DECLARE i INT; SET i = 1; WHILE(i \u0026lt;= 6000010) DO INSERT INTO page (`name`, `content`) VALUES (CONCAT(\u0026#39;小瓦\u0026#39;, i), CONCAT(\u0026#39;xx\u0026#39;, i)); SET i = i + 1; END WHILE; END;; DELIMITER ; -- 调用存储过程 CALL init_page(); 启用慢查询日志 1 2 3 4 5 6 -- 启用慢查询日志 SET GLOBAL slow_query_log=1; -- 将慢查询时间阈值设置为 0.1 秒 SET GLOBAL long_query_time=0.1; -- 查看慢查询日志名 SHOW VARIABLES LIKE \u0026#39;%slow_query%\u0026#39;; 对比 SQL 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 -- 探索一级索引 --- 基础 SQL select * from page order by id limit 6000000, 10; --- 最慢 select * from page where id \u0026gt;= (select id from page order by id limit 6000000, 1) order by id limit 10; --- 最快 select t1.* from page t1, (select id from page order by id limit 6000000, 10) t2 where t1.id = t2.id order by t1.id; -- 探索二级索引 --- 基础 SQL，会是全表扫描，最慢 select * from page order by name limit 6000000, 10; --- 强制走二级索引，稍快 select * from page force index(idx_name) order by name limit 6000000, 10; --- 利用使用了覆盖索引的子查询，减少回表，最快 select t1.* from page t1, (select id from page order by name limit 6000000, 10) t2 where t1.id = t2.id order by t1.name; 查看慢查询日志和数据存储位置 1 2 3 4 5 6 # 查看 mysql 进程参数 ps aux | grep mysql # /opt/homebrew/opt/mariadb/bin/mariadbd --basedir=/opt/homebrew/opt/mariadb --datadir=/opt/homebrew/var/mysql --plugin-dir=/opt/homebrew/opt/mariadb/lib/plugin --log-error=/opt/homebrew/var/mysql/zmz.local.err --pid-file=zmz.local.pid # --basedir=/opt/homebrew/opt/mariadb 即慢查询日志和数据文件所在目录 # ps. 执行前面的存储计划，创建 100 万条数据，占用磁盘空间大约 100MB；创建 600 万条数据，占用空间大约 600MB； 五、References mysql查询 limit 1000,10 和limit 10 速度一样快吗？如果我要分页，我该怎么办？ 要想通过面试，MySQL的Limit子句底层原理你不可不知 MySQL Logical Architecture Mysql index configuration MySQL ORDER BY / LIMIT performance: late row lookups Late Row Lookups: InnoDB MySQL ORDER BY LIMIT Performance Optimization mysql 证明为什么用limit时，offset很大会影响性能 MySQL 5.7 Reference Manual/LIMIT Query Optimization Pagination Optimization We need tool support for keyset pagination ","date":"2022-11-05T12:36:01+08:00","permalink":"https://zhumengzhu.github.io/2022/11/mysql-order-by-limit-performance-optimization/","title":"Mysql 的深分页问题及优化方法"},{"content":"常用命令 hugo new site SITE_NAME 生成静态博客项目 hugo server 启动本地服务器，加上 -D 可以渲染 draft=true 的文章 hugo new post/new-content.md 在 post 下新建一篇文章 hugo 生成站点静态文件(public 和 resources 目录) hugo list drafts/expired/future 列出草稿/过期/未来的文件 踩坑记 使用主题 Event 时, 文章必须放在 content/**post**/ 目录下, 否则 Home 页不会展示文章链接, 文章内也不会展示目录 使用主题 Zzo 时, 要创建 Archive 页(类似 Event 中的 Home 页), 需要创建文件 content/archive/_index.md(参考 How to automatically generate archive page content #47) 使用主题 Zzo 时, 在 GigHub Actions 配置中必须启用 Hugo extended 模式, 否则构建会失败(参考Hugo setup) 参考链接 Hugo 官方文档 Hugo 从入门到会用 Hugo 搭建博客实践 Hugo+Stack 博客修改记录 hugo升级与hugo-theme-stack主题修改与最后修改时间问题 ","date":"2022-10-30T22:22:52+08:00","permalink":"https://zhumengzhu.github.io/2022/10/hugo-quick-start/","title":"Hugo 配置记录"},{"content":"Mac 客户端 推荐 V2rayU Terminal 代理 1 2 # .config/fish/config.fish alias all_proxy=\u0026#39;export http_proxy=http://127.0.0.1:1087;export https_proxy=http://127.0.0.1:1087;export ALL_PROXY=socks5://127.0.0.1:1080\u0026#39; git ssh 代理 1 2 3 4 # .ssh/config Host github.com User git ProxyCommand nc -v -x 127.0.0.1:1080 %h %p ","date":"2022-10-16T19:09:32+08:00","permalink":"https://zhumengzhu.github.io/2022/10/how-to-set-network-proxy/","title":"代理设置"}]