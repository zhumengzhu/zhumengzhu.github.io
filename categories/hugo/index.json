[{"content":"背景 这是一篇博客阅读笔记，原博客Late row lookups: InnoDB写于 2011 年，作者是一个叫 Quassnoi 的俄罗斯人。\nQuassnoi 在 2009 年时写了一篇文章讲 MySQL Limit 的性能优化(MySQL ORDER BY / LIMIT performance: late row lookups)，后来有读者提了两个问题：\nIs this workaround specific to MyISAM engine? How does PostgreSQL handle this? Quassnoi 写下这篇新博客，即为了回答上述两个问题。\n正文 The questions concerns a certain workaround for MySQL LIMIT … OFFSET queries like this:\n1 2 3 4 SELECT * FROM mytable ORDER BY id LIMIT 10 OFFSET 10000; which can be improved using a little rewrite:\n1 2 3 4 5 6 7 8 SELECT m.* FROM (SELECT id FROM mytable ORDER BY id LIMIT 10 OFFSET 10000) q JOIN mytable m ON m.id = q.id ORDER BY m.id; 注意：作者之前的文章讨论的是这个方法对 MyISAM 是有效的；问题是，对于 InnoDB 和 PostgreSQL 呢？\nPostgreSQL The Answer The second questions is easy: PostgreSQL won\u0026rsquo;t pull the fields from the table until it really needs them. If a query involving an ORDER BY along with LIMIT and OFFSET is optimized to use the index for the ORDER BY part, the table lookups won\u0026rsquo;t happen for the records skipped.\n这句话是说，PostgreSQL 只会在需要的时候才回表查询。如果一个查询涉及 ORDER BY、LIMIT 和 OFFSET，那么可以先利用索引跳过不需要的记录，只对需要的记录进行进行回表。\n这其实就是『Late Row Lookups』；与之相对的，MySQL 执行的是『Early Row Lookups』。\n作者后面说虽然 PostgreSQL 的查询计划不会输出回表信息，但可以通过一个简单的测试进行验证。但具体怎么进行这个实验，作者没讲，下面试着做个补充。\n验证(存疑) 建表详情 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 -- 建表 CREATE TABLE page ( id SERIAL PRIMARY KEY, name VARCHAR(16) DEFAULT NULL, content VARCHAR(255) DEFAULT NULL ); -- 为 name 字段创建二级索引 CREATE INDEX idx_name ON page (name); -- 初始化 600 万条数据 INSERT INTO page (name, content) (SELECT CONCAT(\u0026#39;小瓦\u0026#39;, s.id) AS name, CONCAT(\u0026#39;xx\u0026#39;, s.id) AS content FROM GENERATE_SERIES(1, 6000010) AS s(id)); 执行 SQL 一：直接查询 1 2 3 4 5 6 7 postgres=# EXPLAIN ANALYZE SELECT * FROM page ORDER BY id OFFSET 6000000 LIMIT 10; QUERY PLAN ------------------------------------------------------------------------------------------------------------------------------------------ Limit (cost=199830.43..199830.76 rows=10 width=26) (actual time=540.002..540.003 rows=10 loops=1) -\u0026gt; Index Scan using page_pkey on page (cost=0.43..199846.81 rows=6000492 width=26) (actual time=0.087..427.982 rows=6000010 loops=1) Planning Time: 0.108 ms Execution Time: 540.022 ms 执行 SQL 二：使用子查询 1 2 3 4 5 6 7 8 9 10 11 postgres=# EXPLAIN ANALYZE SELECT t1.* FROM page t1, (SELECT id FROM page ORDER BY id OFFSET 6000000 LIMIT 10) t2 where t1.id=t2.id ORDER BY t1.id; QUERY PLAN ---------------------------------------------------------------------------------------------------------------------------------------------------- Nested Loop (cost=155811.47..155895.90 rows=10 width=26) (actual time=368.952..368.960 rows=10 loops=1) -\u0026gt; Limit (cost=155811.04..155811.30 rows=10 width=4) (actual time=368.941..368.942 rows=10 loops=1) -\u0026gt; Index Only Scan using page_pkey on page (cost=0.43..155823.81 rows=6000492 width=4) (actual time=0.015..248.584 rows=6000010 loops=1) Heap Fetches: 50 -\u0026gt; Index Scan using page_pkey on page t1 (cost=0.43..8.45 rows=1 width=26) (actual time=0.001..0.001 rows=1 loops=10) Index Cond: (id = page.id) Planning Time: 0.375 ms Execution Time: 369.004 ms 执行 SQL 三：使用子查询 1 2 3 4 5 6 7 8 9 10 11 postgres=# EXPLAIN ANALYZE SELECT t1.* FROM page t1 join (SELECT id FROM page ORDER BY id OFFSET 6000000 LIMIT 10) t2 ON t1.id=t2.id ORDER BY t1.id; QUERY PLAN ---------------------------------------------------------------------------------------------------------------------------------------------------- Nested Loop (cost=155811.47..155895.90 rows=10 width=26) (actual time=362.645..362.652 rows=10 loops=1) -\u0026gt; Limit (cost=155811.04..155811.30 rows=10 width=4) (actual time=362.633..362.634 rows=10 loops=1) -\u0026gt; Index Only Scan using page_pkey on page (cost=0.43..155823.81 rows=6000492 width=4) (actual time=0.017..243.148 rows=6000010 loops=1) Heap Fetches: 50 -\u0026gt; Index Scan using page_pkey on page t1 (cost=0.43..8.45 rows=1 width=26) (actual time=0.001..0.001 rows=1 loops=10) Index Cond: (id = page.id) Planning Time: 4.609 ms Execution Time: 362.707 ms 三个查询的耗时为：`540.022 ms` vs `369.004 ms` vs `362.707 ms`。 \u003e Tips: 使用 `EXPLAIN ANALYZE` 既可以获得查询计划，又能执行语句。 结论 上述实验可以证明该优化对于 PostgreSQL 同样可以有效。\nInnoDB 为了回答这个问题，作者首先创建了一张表。\n建表 建表详情 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 # 创建一张内存表 CREATE TABLE filler ( id INT NOT NULL PRIMARY KEY AUTO_INCREMENT ) ENGINE = Memory; # 创建 InnoDB 表 CREATE TABLE lookup ( id INT NOT NULL PRIMARY KEY, value INT NOT NULL, shorttxt TEXT NOT NULL, longtxt TEXT NOT NULL ) ENGINE = InnoDB ROW_FORMAT = COMPACT; # 为 value 字段创建索引 CREATE INDEX ix_lookup_value ON lookup (value); # 创建存储计划 DELIMITER $$ CREATE PROCEDURE prc_filler(cnt INT) BEGIN DECLARE _cnt INT; SET _cnt = 1; WHILE _cnt \u0026lt;= cnt DO INSERT INTO filler SELECT _cnt; SET _cnt = _cnt + 1; END WHILE; END $$ # 初始化内存表 DELIMITER ; START TRANSACTION; CALL prc_filler(100000); COMMIT; # 初始化 InnoDB 表 INSERT INTO lookup SELECT id, CEILING(RAND(20110211) * 1000000), RPAD(\u0026#39;\u0026#39;, CEILING(RAND(20110211 \u0026lt;\u0026lt; 1) * 100), \u0026#39;*\u0026#39;), RPAD(\u0026#39;\u0026#39;, CEILING(8192 + RAND(20110211 \u0026lt;\u0026lt; 1) * 100), \u0026#39;*\u0026#39;) FROM filler; 上面利用一张内存表和存储计划创建了一张 InnoDB 表 `lookup`：这张表包含一个加了索引的 `INT` 列，以及两个 `TEXT` 列，其中 shorttxt 存储短字符串(包含 1~100 个字符)，longtxt 存储长字符串(包含 8193~8293 个字符)。 通过主键索引查询 value 和 shottxt 两个字段时，是否使用子查询优化对耗时影响不大，略去不讨论。\n通过主键索引查询 longtxt 列 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # Rewrite SELECT LENGTH(l.longtxt) FROM (SELECT id FROM lookup ORDER BY id LIMIT 10 OFFSET 90000) q JOIN lookup l ON l.id = q.id ORDER BY q.id; # 10 rows in set (0.133 sec) # No rewrite SELECT LENGTH(longtxt) FROM lookup ORDER BY id LIMIT 10 OFFSET 90000; # 10 rows in set (1.579 sec) 0.133 sec vs 1.579 sec。\nWhy such a difference?\nThe reason is that InnoDB, despite the fact it stores the data in the clustered index, is still able to move \u0026gt; some data out of the index. This is called external storage.\n在 InnoDB 中，小于 768 字节的列会全部存储在页上，大于 768 字节则会分开存储。在上面的 lookup 表中，shottxt 列总是 on-page 存储的，而 longtxt 则是 off-page的。\n因此，直接查询 longtxt 时，每扫描一条记录都要出发两次page lookups：第一次查聚簇索引，第二次查外部存储。这既会花费很多时间，也可能破坏 InnoDB 缓存，导致缓存命中率下降。\n通过二级索引查询 shorttxt 列 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # Rewrite SELECT LENGTH(l.shorttxt) FROM (SELECT id, value FROM lookup ORDER BY value LIMIT 10 OFFSET 90000) q JOIN lookup l ON l.id = q.id ORDER BY q.value; # 10 rows in set (0.022 sec) # No rewrite SELECT LENGTH(shorttxt) FROM lookup ORDER BY value LIMIT 10 OFFSET 90000;# 10 rows in set (0.209 sec) 0.022 sec vs 0.209 sec，耗时相差 10 倍。\nInnoDB的二级索引查询有点类似MyISAM，都需要一次额外的回表查询去获取正在的数据。\n上面第一个查询对于跳过的记录不会执行回表查询，因此速度是原来的 10 倍。它甚至比在主键索引上的查询(0.044 sec)还快，原因是二级索引包含的数据比主键索引更少，每页保存的数据更多，因此索引可能更加矮胖，扫描速度更快。\n当然，二级索引上同样是Early Row Lookups。\n结论 A trick used to avoid early row lookups for the LIMIT … OFFSET queries is useful on InnoDB tables too, though to different extent, depending on the ORDER BY condition and the columns involved:\nIt\u0026rsquo;s very useful on queries involving columns stored off-page (long TEXT, BLOB and VARCHAR columns) It\u0026rsquo;s very useful on ORDER BY conditions served by secondary indexes It\u0026rsquo;s quite useful on moderate sized columns (still stored on page) or CPU-intensive expressions It\u0026rsquo;s almost useless on short columns without complex CPU-intensive processing 其它 PostgreSQL查询计划 除第一行以外每个-\u0026gt;表示一个子动作 查询计划的阅读顺序都是从后往前 cost 由 .. 分割成两个数字，第一个数字表示启动成本，即返回第一行的成本；第二个数字表示返回所有数据的成本。 rows 表示返回行数 width 表示每行平均宽度 loops 表示索引扫描被执行过几次 Reference Documentation: 15: 14.1. Using EXPLAIN - PostgreSQL ","description":"阅读博客『Late Row Lookups: InnoDB』的笔记","id":0,"section":"post","tags":["Notes","MySQL","Performance","Optimization","Late Row Lookups","InnoDB","PostgreSQL"],"title":"【笔记】Late Row Lookups: InnoDB","uri":"https://zhumengzhu.github.io/2022/11/late-row-lookups-innodb/"},{"content":"一、深分页为什么慢 深分页指的是形如 select ... from ... where ... order by ... limit offset, size 的查询语句中 offset 特别大的情况。高性能 MySQL(第三版) 的第 6.7.5 节专门讲了此问题，但比较简略。\n有多慢 假设有一张 page 表包含 600 多万条数据，分别执行下面两条语句：\n1 2 3 4 5 6 7 # SQL 一 select * from page order by id limit 0, 10; # 10 rows in set (0.001 sec) # SQL 二 select * from page order by id limit 6000000, 10; # 10 rows in set (0.940 sec) 注意到 SQL 二其实是按主键 ID 排序的(意味着不需要进行 filesort，直接按主键索引顺序扫描即可)，耗时仍然高达 0.940 秒。\n为什么慢 『查询计划』\n1 2 3 4 5 6 explain select * from page order by id limit 6000000, 10; +------+-------------+-------+-------+---------------+---------+---------+------+---------+-------+ | id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra | +------+-------------+-------+-------+---------------+---------+---------+------+---------+-------+ | 1 | SIMPLE | page | index | NULL | PRIMARY | 4 | NULL | 5988448 | | +------+-------------+-------+-------+---------------+---------+---------+------+---------+-------+ 『慢查询日志』\n1 2 3 4 5 6 7 # Time: 221106 0:26:54 # User@Host: root[root] @ localhost [] # Thread_id: 18 Schema: test QC_hit: No # Query_time: 0.939618 Lock_time: 0.000735 Rows_sent: 10 Rows_examined: 6000010 # Rows_affected: 0 Bytes_sent: 533 SET timestamp=1667665614; select * from page order by id limit 6000000, 10; 注意到 rows 和 为 rows_examined 分别为 5988448、6000010。\n原因显而易见：为了完成 limit offset, size 这样的查询， MySQL 要扫描至少 offset + size 行数据；offset 越大，则扫描次数越多，速度越慢。\n二、深分页怎么优化 分页从原理上来讲，主要是两种：\n一种就是前面讲的基于 limit offset, size 的分页，英文一般叫 offset pagination； 另一种方法放弃了 offset，改用 left off, SQL 形如 SELECT ... WHERE ... AND id \u0026lt; $left_off ORDER BY id DESC LIMIT 10, 英文一般叫 cursor pagination, 也有人称之为 seek method 或 keyset pagination。 Offset pagination 就像基于比较的排序算法的平均时间复杂度的下界是 O(nlogn) 一样，对于 MySQL 来说，凡是形如 limit offset, size 的查询，扫描次数的下限就是 offset + size，我们只能尽量逼近这个下限。\n由于在主键索引上的优化比较复杂，同样的 SQL 对于不同的数据规模效果不一样，暂不讨论。这里主要分析在二级索引上的优化。\n对于拥有 600 多万条数据的 page 表：\n1 2 3 4 5 6 7 8 9 10 -- 原 SQL(强制走二级索引) select * from page force index(idx_name) order by name limit 6000000, 10; # 10 rows in set (4.833 sec) -- 优化方案一 select t1.* from page t1, (select id from page order by name limit 6000000, 10) t2 where t1.id = t2.id order by t1.name; # 10 rows in set (0.746 sec) -- 优化方案二 select t1.* from page t1 join (select id from page order by name limit 6000000, 10) t2 on t1.id = t2.id order by t1.name; # 10 rows in set (0.741 sec) 通过使用利用了覆盖索引的子查询，性能提升约 80%~90%：\nKeyset pagination 1 2 3 4 # First page (latest 10 items): SELECT ... WHERE ... ORDER BY id DESC LIMIT 10 # Next page (second 10): SELECT ... WHERE ... AND id \u0026lt; $left_off ORDER BY id DESC LIMIT 10 三、优化为什么有效 优化前 考虑原始 SQL select * from page force index(idx_name) order by name limit 6000000, 10 的执行过程：\n首先 Sever 层向 InnoDB 请求第一条数据；InnoDB 从 idx_name 上获取第一条二级索引记录，然后查询聚簇索引获取完整记录(即回表操作)，返回给 Server 层; 由于存在 limit 6000000 的限制, Server 层会将该数据丢弃并计数，然后向 InnoDB 请求下一条数据； 上述操作重复 600 万次； 之后的第 6000001~6000010 10 条数据则会被放入本地网络缓冲区，发给客户端； 问题在第 1 步的回表操作：\n回表首先意味着先读一次二级索引，然后读一次聚簇索引，因此记录的扫描总数实际会是 2 * 600 万次=1200 万次； 其次，回表操作可能需要一次磁盘随机读； 优化后 再考虑优化后的 SQL select t1.* from page t1 join (select id from page order by name limit 6000000, 10) t2 on t1.id = t2.id order by t1.name 的执行过程：\n首先 Sever 层向 InnoDB 请求第一条数据；InnoDB 从 idx_name 上获取第一条二级索引记录，然后查询聚簇索引获取完整记录(这一操作叫回表)，然后将主键 ID 返回给 Server 层; 由于存在 limit 6000000 的限制, Server 层会将该数据丢弃并计数，然后向 InnoDB 请求下一条数据； 上述操作重复 600 万次； 之后的第 6000001~6000010 10 条数据则会被放入内存缓冲区； 查询聚簇索引，获取 10 个主键 ID 对应的完整记录； 总结 在优化后：\n记录的总扫描次数从 1200 万次 减少到 600 万零 10 次； 磁盘随机读的次数从 600 万次 减少到 10 次； 四、试验方法 建表和数据初始化 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 -- 建表 CREATE TABLE `page` ( `id` INT(11) NOT NULL AUTO_INCREMENT, `name` VARCHAR(16) DEFAULT NULL, `content` VARCHAR(255) DEFAULT NULL, PRIMARY KEY (`id`), KEY `idx_name` (`name`) ) ENGINE = InnoDB DEFAULT CHARSET = utf8mb4; -- 创建存储过程用于初始化数据 DELIMITER ;; CREATE PROCEDURE init_page() BEGIN DECLARE i INT; SET i = 1; WHILE(i \u0026lt;= 6000010) DO INSERT INTO page (`name`, `content`) VALUES (CONCAT(\u0026#39;小瓦\u0026#39;, i), CONCAT(\u0026#39;xx\u0026#39;, i)); SET i = i + 1; END WHILE; END;; DELIMITER ; -- 调用存储过程 CALL init_page(); 启用慢查询日志 1 2 3 4 5 6 -- 启用慢查询日志 SET GLOBAL slow_query_log=1; -- 将慢查询时间阈值设置为 0.1 秒 SET GLOBAL long_query_time=0.1; -- 查看慢查询日志名 SHOW VARIABLES LIKE \u0026#39;%slow_query%\u0026#39;; 对比 SQL 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 -- 探索一级索引 --- 基础 SQL select * from page order by id limit 6000000, 10; --- 最慢 select * from page where id \u0026gt;= (select id from page order by id limit 6000000, 1) order by id limit 10; --- 最快 select t1.* from page t1, (select id from page order by id limit 6000000, 10) t2 where t1.id = t2.id order by t1.id; -- 探索二级索引 --- 基础 SQL，会是全表扫描，最慢 select * from page order by name limit 6000000, 10; --- 强制走二级索引，稍快 select * from page force index(idx_name) order by name limit 6000000, 10; --- 利用使用了覆盖索引的子查询，减少回表，最快 select t1.* from page t1, (select id from page order by name limit 6000000, 10) t2 where t1.id = t2.id order by t1.name; 查看慢查询日志和数据存储位置 1 2 3 4 5 6 # 查看 mysql 进程参数 ps aux | grep mysql # /opt/homebrew/opt/mariadb/bin/mariadbd --basedir=/opt/homebrew/opt/mariadb --datadir=/opt/homebrew/var/mysql --plugin-dir=/opt/homebrew/opt/mariadb/lib/plugin --log-error=/opt/homebrew/var/mysql/zmz.local.err --pid-file=zmz.local.pid # --basedir=/opt/homebrew/opt/mariadb 即慢查询日志和数据文件所在目录 # ps. 执行前面的存储计划，创建 100 万条数据，占用磁盘空间大约 100MB；创建 600 万条数据，占用空间大约 600MB； 五、References mysql查询 limit 1000,10 和limit 10 速度一样快吗？如果我要分页，我该怎么办？ 要想通过面试，MySQL的Limit子句底层原理你不可不知 MySQL Logical Architecture Mysql index configuration MySQL ORDER BY / LIMIT performance: late row lookups Late Row Lookups: InnoDB MySQL ORDER BY LIMIT Performance Optimization mysql 证明为什么用limit时，offset很大会影响性能 MySQL 5.7 Reference Manual/LIMIT Query Optimization Pagination Optimization We need tool support for keyset pagination ","description":"讨论 MySQL 深分页查询为什么慢，及如何优化","id":1,"section":"post","tags":["Notes","MySQL","Performance","Optimization","High offset","Keyset Pagination"],"title":"Mysql 的深分页问题及优化方法","uri":"https://zhumengzhu.github.io/2022/11/mysql-order-by-limit-performance-optimization/"},{"content":"一个有点懒、有点笨，又爱刨根问底的程序员。\n","description":"about page","id":2,"section":"","tags":null,"title":"About","uri":"https://zhumengzhu.github.io/about/"},{"content":"常用命令 hugo new site SITE_NAME 生成静态博客项目 hugo server 启动本地服务器，加上 -D 可以渲染 draft=true 的文章 hugo new post/new-content.md 在 post 下新建一篇文章 hugo 生成站点静态文件(public 和 resources 目录) hugo list drafts/expired/future 列出草稿/过期/未来的文件 踩坑记 使用主题 Event 时, 文章必须放在 content/**post**/ 目录下, 否则 Home 页不会展示文章链接, 文章内也不会展示目录 使用主题 Zzo 时, 要创建 Archive 页(类似 Event 中的 Home 页), 需要创建文件 content/archive/_index.md(参考 How to automatically generate archive page content #47) 使用主题 Zzo 时, 在 GigHub Actions 配置中必须启用 Hugo extended 模式, 否则构建会失败(参考Hugo setup) 参考链接 Hugo 从入门到会用 Hugo 搭建博客实践 Hugo 官方文档 ","description":"记录我在用 Hugo 搭建博客时常用的一些命令，踩到的坑，解决方法等","id":3,"section":"post","tags":["Notes","Hugo"],"title":"我的 Hugo 配置笔记","uri":"https://zhumengzhu.github.io/2022/10/hugo-quick-start/"},{"content":"Mac 客户端 推荐 V2rayU Terminal 代理 1 2 # .config/fish/config.fish alias all_proxy=\u0026#39;export http_proxy=http://127.0.0.1:1087;export https_proxy=http://127.0.0.1:1087;export ALL_PROXY=socks5://127.0.0.1:1080\u0026#39; git ssh 代理 # .ssh/config Host github.com User git ProxyCommand nc -v -x 127.0.0.1:1080 %h %p ","description":"记录我的网络代理设置","id":4,"section":"post","tags":["Notes","Network","Git","Proxy"],"title":"我的代理设置","uri":"https://zhumengzhu.github.io/2022/10/how-to-set-network-proxy/"}]